{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/twitter_sentiments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id  label                                              tweet\n0   1      0   @user when a father is dysfunctional and is s...\n1   2      0  @user @user thanks for #lyft credit i can't us...\n2   3      0                                bihday your majesty\n3   4      0  #model   i love u take with u all the time in ...\n4   5      0             factsguide: society now    #motivation",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(31962, 3)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    29720\n1     2242\nName: label, dtype: int64"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size = 0.2, stratify = data['label'], random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((25569, 3), (6393, 3))"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    0.929837\n1    0.070163\nName: label, dtype: float64"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "train.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    0.929923\n1    0.070077\nName: label, dtype: float64"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "test.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(lowercase= True, max_features=1000, stop_words=ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "TfidfVectorizer(max_features=1000,\n                stop_words=frozenset({'a', 'about', 'above', 'across', 'after',\n                                      'afterwards', 'again', 'against', 'all',\n                                      'almost', 'alone', 'along', 'already',\n                                      'also', 'although', 'always', 'am',\n                                      'among', 'amongst', 'amoungst', 'amount',\n                                      'an', 'and', 'another', 'any', 'anyhow',\n                                      'anyone', 'anything', 'anyway',\n                                      'anywhere', ...}))"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "tfidf_vectorizer.fit(train.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idf = tfidf_vectorizer.transform(train.tweet)\n",
    "test_idf  = tfidf_vectorizer.transform(test.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LogisticRegression()"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model_LR.fit(train_idf, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = model_LR.predict(train_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = model_LR.predict(test_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.48840927258193445"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# f1 score on train data\n",
    "f1_score(y_true= train.label, y_pred= predict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.46003262642740617"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "f1_score(y_true= test.label, y_pred= predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps= [('tfidf', TfidfVectorizer(lowercase=True,\n",
    "                                                      max_features=1000,\n",
    "                                                      stop_words= ENGLISH_STOP_WORDS)),\n",
    "                            ('model', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('tfidf',\n                 TfidfVectorizer(max_features=1000,\n                                 stop_words=frozenset({'a', 'about', 'above',\n                                                       'across', 'after',\n                                                       'afterwards', 'again',\n                                                       'against', 'all',\n                                                       'almost', 'alone',\n                                                       'along', 'already',\n                                                       'also', 'although',\n                                                       'always', 'am', 'among',\n                                                       'amongst', 'amoungst',\n                                                       'amount', 'an', 'and',\n                                                       'another', 'any',\n                                                       'anyhow', 'anyone',\n                                                       'anything', 'anyway',\n                                                       'anywhere', ...}))),\n                ('model', LogisticRegression())])"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "pipeline.fit(train.tweet, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 0, 0, ..., 0, 0, 0])"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "pipeline.predict(train.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"Marcus Rashford and Wayne Rooney were the best paired strikers of Manchester United\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0])"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "pipeline.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['text_classification.joblib']"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "dump(pipeline, filename=\"text_classification.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          id  label                                              tweet\n13        14      1  @user #cnn calls #michigan middle school 'buil...\n14        15      1  no comment!  in #australia   #opkillingbay #se...\n17        18      1                             retweet if you agree! \n23        24      1    @user @user lumpy says i am a . prove it lumpy.\n34        35      1  it's unbelievable that in the 21st century we'...\n...      ...    ...                                                ...\n31934  31935      1  lady banned from kentucky mall. @user  #jcpenn...\n31946  31947      1  @user omfg i'm offended! i'm a  mailbox and i'...\n31947  31948      1  @user @user you don't have the balls to hashta...\n31948  31949      1   makes you ask yourself, who am i? then am i a...\n31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n\n[2242 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>1</td>\n      <td>@user #cnn calls #michigan middle school 'buil...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>1</td>\n      <td>no comment!  in #australia   #opkillingbay #se...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>1</td>\n      <td>retweet if you agree!</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>1</td>\n      <td>@user @user lumpy says i am a . prove it lumpy.</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>35</td>\n      <td>1</td>\n      <td>it's unbelievable that in the 21st century we'...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>31934</th>\n      <td>31935</td>\n      <td>1</td>\n      <td>lady banned from kentucky mall. @user  #jcpenn...</td>\n    </tr>\n    <tr>\n      <th>31946</th>\n      <td>31947</td>\n      <td>1</td>\n      <td>@user omfg i'm offended! i'm a  mailbox and i'...</td>\n    </tr>\n    <tr>\n      <th>31947</th>\n      <td>31948</td>\n      <td>1</td>\n      <td>@user @user you don't have the balls to hashta...</td>\n    </tr>\n    <tr>\n      <th>31948</th>\n      <td>31949</td>\n      <td>1</td>\n      <td>makes you ask yourself, who am i? then am i a...</td>\n    </tr>\n    <tr>\n      <th>31960</th>\n      <td>31961</td>\n      <td>1</td>\n      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2242 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "data[data.label == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}